---
title: "Normalization"
author: "Miao Yu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = T)
```

## Demo data

We prepared 5 NIST 1950 samples and 6 matrix blank samples as demodata.

```{r}
library(rmwf)
data("mzrt")
# impute the data
mzrt$data <- enviGCMS::getimputation(mzrt)$data
```

## Check the data

Here we use Relative Log Abundance (RLA) plots, relative Log Abundance Ridge (RLAR) plots, and PCA visualization to check the data.

```{r ba}
# visualize the batch effect
enviGCMS::plotrla(mzrt$data,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(mzrt$data,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(mzrt$data,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

## Correction

### Functions

Here is functions for 17 normalization / batch correction methods.

```{r}
# PMID: 16762068
# None
limmafit <- function(data, lv, batch = NULL,log=F){
        if(log) data <- log(data+1)
        mod <- stats::model.matrix(~lv)
        mod0 <- as.matrix(rep(1,length(lv)))
        datacor <- signal <- error <- pValues <-  qValues <- NULL
        if(is.null(batch)){
                batch <- NULL
                # limma fit
                lmfit <- limma::lmFit(data, mod)
                signal <- lmfit$coef[, 1:nlevels(lv)] %*% t(mod[, 1:nlevels(lv)])
                error <- data - signal
                datacor <- signal + error
                rownames(signal) <- rownames(error) <- rownames(data)
                colnames(signal) <- colnames(error) <- colnames(data)
                # find the peaks with significant differences by F test
                # with BH correction for fdr control without correction
                pValues = sva::f.pvalue(as.matrix(data), mod, mod0)
                qValues = stats::p.adjust(pValues, method = "BH")
        }else{
                modcor <- cbind(mod,batch)
                modcor0 <- cbind(mod0,batch)
                lmfit <- limma::lmFit(data, modcor)
                # data decomposition with batch
                batch <- lmfit$coef[, (nlevels(lv) + 1):(nlevels(lv) + NCOL(batch))] %*% t(modcor[, (nlevels(lv) + 1):(nlevels(lv) + NCOL(batch))])
                signal <- lmfit$coef[, 1:nlevels(lv)] %*% t(modcor[, 1:nlevels(lv)])
                error <- data - signal - batch
                datacor <- signal + error
                rownames(datacor) <- rownames(batch) <- rownames(signal) <- rownames(error) <- rownames(data)
                colnames(datacor) <- colnames(batch) <- colnames(signal) <- colnames(error) <- colnames(data)

                # find the peaks with significant differences by F test
                # with BH correction for fdr control
                pValues = sva::f.pvalue(as.matrix(data), modcor, modcor0)
                qValues = stats::p.adjust(pValues, method = "BH")
        }
        # get the results as list
        li <- list(data, datacor, signal, batch, error, pValues, qValues)
        names(li) <- c("data","dataCorrected","signal","batch", "error", "p-values", "q-values")
        return(li)
}

# normalize to zero mean and unit variance

AutoScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sd(x, na.rm=T)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# normalize to zero mean and squared root variance

ParetoScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sqrt(sd(x, na.rm=T))))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# normalize to zero mean but variance/SE

RangeScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/(max(x)-min(x))))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# vast scaling

VastScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sd(x, na.rm=T) * mean(x)/sd(x, na.rm=T)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# level scaling

LevelScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/mean(x)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# total sum row

TotalSum <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/sum(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# Median row

MedianNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/median(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# Mean row

MeanNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/mean(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# PQN

PQNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        ref <- apply(data[,lv == lv[1]],1,mean)
        data2 <- apply(data, 2, function(x) x/median(as.numeric(x/ref), na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}

# VSN

VSNNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        fit <- vsn::vsnMatrix(data)
        data2 <- fit@hx
        li <- limmafit(data2,lv)
        return(li)
}

# Quantile

QuanNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- preprocessCore::normalize.quantiles(as.matrix(data), copy=FALSE)
        li <- limmafit(data2,lv)
        return(li)
}

# lumi rsn

LumiRobustSpline <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- lumi::rsn(data)
        li <- limmafit(data2,lv)
        return(li)
}

# Limma CyclicLoess
LimmaCyclicLoess <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- limma::normalizeCyclicLoess(data)
        li <- limmafit(data2,lv)
        return(li)
}
# AFFA CUBICSpline
LimmaCubicSpline <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- affy::normalize.qspline(data)
        li <- limmafit(data2,lv)
        return(li)
}
# SVA
svacor <- function(data,lv,log=T) {
        if(log) data <- log(data+1)
        mod <- stats::model.matrix(~lv)
        svafit <- sva::sva(data, mod)
        if (svafit$n.sv == 0) {
                message("No surrogate variable found")
                li <- limmafit(data,lv)
        } else {
                message("Data is correcting ...")
                batch <- svafit$sv
                li <- limmafit(data,lv,batch)
                message("Done!")
        }
        return(li)
}
# iSVA
isvacor <- function(data, lv,log=T) {
        if(log) data <- log(data+1)
        isvafit <- try(isva::DoISVA(data, lv, factor.log = T),T)
        if(class(isvafit) == 'try-error') {
                li <- limmafit(data,lv)
        }else{
                if (isvafit$nsv == 0) {
                        message("No surrogate variable found or error for computation.")
                        li <- limmafit(data,lv)
                } else {
                        message("Data is correcting ...")
                        batch <- isvafit$isv
                        li <- limmafit(data,lv,batch)
                        message("Done!")
                }
        }
        return(li)
}
# PCR
pcacor <- function(data, lv,log=T) {
        if(log) data <- log(data+1)
        batch <- svd(data - rowMeans(data))$v[,1]
        message("Data is correcting ...")
        li <- limmafit(data,lv,batch)
        message("Done!")
        return(li)
}

```

### Batch Correction / Normalization

Here is the normalization process.

```{r}
re0 <- limmafit(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re1 <- AutoScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re2 <- ParetoScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re3 <- RangeScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re4 <- VastScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re5 <- LevelScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re6 <- TotalSum(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re7 <- MedianNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re8 <- MeanNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re9 <- PQNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re10 <- VSNNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re11 <- QuanNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re12 <- LumiRobustSpline(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re13 <- LimmaCyclicLoess(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re14 <- LimmaCubicSpline(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re15 <- try(svacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group)),T)

re16 <- isvacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group))

re17 <- pcacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
```

## Compare the results

Here we use Relative Log Abundance (RLA) plots, relative Log Abundance Ridge (RLAR) plots, and PCA visualization to show the results of normalization.

```{r}
# normalize to zero mean and unit variance
enviGCMS::plotrla(re1$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re1$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re1$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# normalize to zero mean and squared root variance
enviGCMS::plotrla(re2$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re2$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re2$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# normalize to zero mean but variance/SE
enviGCMS::plotrla(re3$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re3$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re3$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# vast scaling
enviGCMS::plotrla(re4$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re4$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re4$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# level scaling
enviGCMS::plotrla(re5$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re5$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re5$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# total sum row
enviGCMS::plotrla(re6$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re6$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re6$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Median row
enviGCMS::plotrla(re7$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re7$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re7$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Mean row
enviGCMS::plotrla(re8$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re8$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re8$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# PQN
enviGCMS::plotrla(re9$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re9$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re9$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# VSN
enviGCMS::plotrla(re10$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re10$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re10$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Quantile
enviGCMS::plotrla(re11$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re11$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re11$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# lumi rsn
enviGCMS::plotrla(re12$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re12$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re12$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Limma CyclicLoess
enviGCMS::plotrla(re13$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re13$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re13$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# AFFA CUBICSpline
enviGCMS::plotrla(re14$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re14$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re14$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# SVA
enviGCMS::plotrla(re15$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re15$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re15$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# iSVA
enviGCMS::plotrla(re16$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re16$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re16$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# PCR
enviGCMS::plotrla(re17$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re17$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re17$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

## Data with QCs

A regression or any machine learning models can be built on QC samples to capture the trend or shift during the injection or different batches. Then such model can be used to predict the trends in the real samples for each peak and the corrected data can be accessed by removing such trends. You will need the injection order for such QC based batch correction method.

Here is an example using loess model to capture the trend and you can use any other prediction models with parameters optimization to generate a better batch correction model based on QC samples.

```{r}
# load the demo data
data(mzrt)
mzrt <- enviGCMS::getimputation(mzrt)
# assign an order and sample 1, 3, 5, 7, 10 were treated as QC samples
orderqc <- c(1,3,5,7,10)
orderall <- c(1:10)
# train the model with QC samples
qc <- t(mzrt$data[,orderqc])
data <- t(mzrt$data)
## variable selection by loess model
cordata <- data.frame()
for(i in seq_along(mzrt$mz)){
mytrain <- loess(qc[,i]~orderqc)
dt <- predict(mytrain,orderall)/data[,i]
cordata <- rbind.data.frame(cordata,dt)
}
colnames(cordata) <- colnames(mzrt$data)
rownames(cordata) <- rownames(mzrt$data)
# get the corrected data
mzrt$dataCorrected <- cordata
# visualization
enviGCMS::plotrla(mzrt$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(mzrt$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(mzrt$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

