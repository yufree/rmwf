---
title: "Normalization"
author: "Miao Yu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = T)
```

## Demo data

We prepared 5 NIST 1950 samples and 5 matrix blank samples as demo data.

```{r}
library(rmwf)
data("mzrt")
# impute the data
mzrt$data <- enviGCMS::getimputation(mzrt)$data
```

## Check the data

Here we use Relative Log Abundance (RLA) plots, relative Log Abundance Ridge (RLAR) plots, and PCA visualization to check the data.

```{r ba}
# visualize the batch effect
enviGCMS::plotrla(mzrt$data,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(mzrt$data,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(mzrt$data,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

## Correction

### Data with QCs/Run order/Batch

A regression or any machine learning models can be built on QC samples/Run order/Batch to capture the trend or shift during the injection or different batches. Then such model can be used to predict the trends in the real samples for each peak and the corrected data can be accessed by removing such trends. You will also need the injection order for such QC based batch correction method.

Here is an example using loess or spline model to capture the trend and you can use any other prediction models with parameters optimization to generate a better batch correction model based on QC samples.

```{r}
# load the demo data
data(mzrt)
mzrt <- enviGCMS::getimputation(mzrt)
# assign an order and sample 1, 3, 5, 7, 10 were treated as QC samples
orderqc <- c(1,3,5,7,10)
orderall <- c(1:10)
# train the model with QC samples, you can perform the log transformation if the data are not follow normal distribution
qc <- t(mzrt$data[,orderqc])
data <- t(mzrt$data)
## build loess model on each peak
loessbc <- function(i){
        mytrain <- loess(qc[,i]~orderqc)
        dt <- predict(mytrain,orderall)-data[,i]+median(data[,i])
        return(dt)
}
## build spline model on each peak
smoothsplinebc <- function(i){
        mytrain <- smooth.spline(qc[,i]~orderqc,cv = T)
        dt <- predict(mytrain,orderall)$y-data[,i]+median(data[,i])
        return(dt)
}

cordata <- BiocParallel::bplapply(c(1:ncol(data)),loessbc)
dataCorrected <- do.call(cbind,cordata)
colnames(dataCorrected) <- colnames(data)

cordata <- BiocParallel::bplapply(c(1:ncol(data)),smoothsplinebc)
dataCorrected2 <- do.call(cbind,cordata)
colnames(dataCorrected2) <- colnames(data)

# visualization
enviGCMS::plotrla(t(dataCorrected),lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(t(dataCorrected),lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(t(dataCorrected),lv = as.numeric(as.factor(mzrt$group$sample_group)))

enviGCMS::plotrla(t(dataCorrected2),lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(t(dataCorrected2),lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(t(dataCorrected2),lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

Here is another method using ComBat method when you know the batch information.

```{r}
# load the demo data
data(mzrt)
mzrt <- enviGCMS::getimputation(mzrt)
# assign batch information
batch <- c(1,1,2,2,1,1,2,2,1,2)
# Using combat method for batch correction
data <- mzrt$data
dataCorrected <- sva::ComBat(data,batch)
# visualization
enviGCMS::plotrla(dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

### Data without QCs/run order/batch information

Here is functions for 17 normalization / batch correction methods.

```{r}
# PMID: 16762068
# None
limmafit <- function(data, lv, batch = NULL,log=F){
        if(log) data <- log(data+1)
        mod <- stats::model.matrix(~lv)
        mod0 <- as.matrix(rep(1,length(lv)))
        datacor <- signal <- error <- pValues <-  qValues <- NULL
        if(is.null(batch)){
                batch <- NULL
                # limma fit
                lmfit <- limma::lmFit(data, mod)
                signal <- lmfit$coef[, 1:nlevels(lv)] %*% t(mod[, 1:nlevels(lv)])
                error <- data - signal
                datacor <- signal + error
                rownames(signal) <- rownames(error) <- rownames(data)
                colnames(signal) <- colnames(error) <- colnames(data)
                # find the peaks with significant differences by F test
                # with BH correction for fdr control without correction
                pValues = sva::f.pvalue(as.matrix(data), mod, mod0)
                qValues = stats::p.adjust(pValues, method = "BH")
        }else{
                modcor <- cbind(mod,batch)
                modcor0 <- cbind(mod0,batch)
                lmfit <- limma::lmFit(data, modcor)
                # data decomposition with batch
                batch <- lmfit$coef[, (nlevels(lv) + 1):(nlevels(lv) + NCOL(batch))] %*% t(modcor[, (nlevels(lv) + 1):(nlevels(lv) + NCOL(batch))])
                signal <- lmfit$coef[, 1:nlevels(lv)] %*% t(modcor[, 1:nlevels(lv)])
                error <- data - signal - batch
                datacor <- signal + error
                rownames(datacor) <- rownames(batch) <- rownames(signal) <- rownames(error) <- rownames(data)
                colnames(datacor) <- colnames(batch) <- colnames(signal) <- colnames(error) <- colnames(data)

                # find the peaks with significant differences by F test
                # with BH correction for fdr control
                pValues = sva::f.pvalue(as.matrix(data), modcor, modcor0)
                qValues = stats::p.adjust(pValues, method = "BH")
        }
        # get the results as list
        li <- list(data, datacor, signal, batch, error, pValues, qValues)
        names(li) <- c("data","dataCorrected","signal","batch", "error", "p-values", "q-values")
        return(li)
}
# normalize to zero mean and unit variance
AutoScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sd(x, na.rm=T)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# normalize to zero mean and squared root variance
ParetoScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sqrt(sd(x, na.rm=T))))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# normalize to zero mean but variance/SE
RangeScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/(max(x)-min(x))))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# vast scaling
VastScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/sd(x, na.rm=T) * mean(x)/sd(x, na.rm=T)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# level scaling
LevelScaling <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- t(apply(data, 1, function(x) (x - mean(x))/mean(x)))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# total sum row
TotalSum <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/sum(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# Median row
MedianNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/median(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# Mean row
MeanNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        data2 <- apply(data, 2, function(x) x/mean(x, na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# PQN
PQNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        r <- rownames(data)
        c <- colnames(data)
        ref <- apply(data[,lv == lv[1]],1,mean)
        data2 <- apply(data, 2, function(x) x/median(as.numeric(x/ref), na.rm=T))
        rownames(data2) <- r
        colnames(data2) <- c
        li <- limmafit(data2,lv)
        return(li)
}
# VSN
VSNNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        fit <- vsn::vsnMatrix(data)
        data2 <- fit@hx
        li <- limmafit(data2,lv)
        return(li)
}
# Quantile
QuanNorm <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- preprocessCore::normalize.quantiles(as.matrix(data), copy=FALSE)
        li <- limmafit(data2,lv)
        return(li)
}
# lumi rsn
LumiRobustSpline <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- lumi::rsn(data)
        li <- limmafit(data2,lv)
        return(li)
}
# Limma CyclicLoess
LimmaCyclicLoess <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- limma::normalizeCyclicLoess(data)
        li <- limmafit(data2,lv)
        return(li)
}
# AFFA CUBICSpline
LimmaCubicSpline <- function(data,lv,log=T){
        if(log) data <- log(data+1)
        data2 <- affy::normalize.qspline(data)
        li <- limmafit(data2,lv)
        return(li)
}
# SVA
svacor <- function(data,lv,log=T) {
        if(log) data <- log(data+1)
        mod <- stats::model.matrix(~lv)
        svafit <- sva::sva(data, mod)
        if (svafit$n.sv == 0) {
                message("No surrogate variable found")
                li <- limmafit(data,lv)
        } else {
                message("Data is correcting ...")
                batch <- svafit$sv
                li <- limmafit(data,lv,batch)
                message("Done!")
        }
        return(li)
}
# iSVA
isvacor <- function(data, lv,log=T) {
        if(log) data <- log(data+1)
        isvafit <- try(isva::DoISVA(data, lv, factor.log = T),T)
        if(class(isvafit) == 'try-error') {
                li <- limmafit(data,lv)
        }else{
                if (isvafit$nsv == 0) {
                        message("No surrogate variable found or error for computation.")
                        li <- limmafit(data,lv)
                } else {
                        message("Data is correcting ...")
                        batch <- isvafit$isv
                        li <- limmafit(data,lv,batch)
                        message("Done!")
                }
        }
        return(li)
}
# PCR
pcacor <- function(data, lv,log=T) {
        if(log) data <- log(data+1)
        batch <- svd(data - rowMeans(data))$v[,1]
        message("Data is correcting ...")
        li <- limmafit(data,lv,batch)
        message("Done!")
        return(li)
}
```

Here is the normalization process.

```{r}
re0 <- limmafit(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# normalize to zero mean and unit variance
re1 <- AutoScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# normalize to zero mean and squared root variance
re2 <- ParetoScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# normalize to zero mean but variance/SE
re3 <- RangeScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# vast scaling
re4 <- VastScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# level scaling
re5 <- LevelScaling(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# total sum row
re6 <- TotalSum(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# Median row
re7 <- MedianNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# Mean row
re8 <- MeanNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# PQN
re9 <- PQNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# VSN
re10 <- VSNNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# Quantile
re11 <- QuanNorm(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# lumi rsn
re12 <- LumiRobustSpline(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# Limma CyclicLoess
re13 <- LimmaCyclicLoess(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# AFFA CUBICSpline
re14 <- LimmaCubicSpline(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# SVA
re15 <- try(svacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group)),T)
# iSVA
re16 <- isvacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
# PCR
re17 <- pcacor(as.matrix(mzrt$data),factor(mzrt$group$sample_group))
```

## Compare the results

Here we use Relative Log Abundance (RLA) plots, relative Log Abundance Ridge (RLAR) plots, and PCA visualization to show the results of normalization for the data without QCs/Run Order/Batch information.

```{r}
# normalize to zero mean and unit variance
enviGCMS::plotrla(re1$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re1$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re1$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# normalize to zero mean and squared root variance
enviGCMS::plotrla(re2$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re2$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re2$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# normalize to zero mean but variance/SE
enviGCMS::plotrla(re3$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re3$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re3$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# vast scaling
enviGCMS::plotrla(re4$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re4$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re4$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# level scaling
enviGCMS::plotrla(re5$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re5$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re5$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# total sum row
enviGCMS::plotrla(re6$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re6$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re6$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Median row
enviGCMS::plotrla(re7$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re7$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re7$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Mean row
enviGCMS::plotrla(re8$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re8$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re8$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# PQN
enviGCMS::plotrla(re9$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re9$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re9$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# VSN
enviGCMS::plotrla(re10$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re10$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re10$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Quantile
enviGCMS::plotrla(re11$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re11$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re11$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# lumi rsn
enviGCMS::plotrla(re12$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re12$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re12$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# Limma CyclicLoess
enviGCMS::plotrla(re13$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re13$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re13$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# AFFA CUBICSpline
enviGCMS::plotrla(re14$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re14$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re14$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# SVA
enviGCMS::plotrla(re15$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re15$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re15$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# iSVA
enviGCMS::plotrla(re16$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re16$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re16$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))

# PCR
enviGCMS::plotrla(re17$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotridges(re17$dataCorrected,lv = as.factor(mzrt$group$sample_group))
enviGCMS::plotpca(re17$dataCorrected,lv = as.numeric(as.factor(mzrt$group$sample_group)))
```

