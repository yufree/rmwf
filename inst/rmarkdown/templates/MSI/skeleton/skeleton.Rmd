---
title: "MSI"
author: "Miao Yu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = FALSE)
```

```{r}
# load function for workflow
source('helper.r')
```

# Raw data

## Reference peaks

Peaks from all pixels will be added together as one super pixel for reference peak picking. 

The input is the raw data and the output is the super pixel data with m/z, ccs and intensity as csv file.

```{r}
# set the path to the .d folder
path = 'PATH_TO_RAW.d'
# set the dll/so file path
libpath = './'
# set the output file name
outref = 'refpeak.csv'
# set the coord output file name
outcoord = 'coord.csv'
# accept Bruker's lisence
accept_Bruker_EULA_and_on_Windows_or_Linux = TRUE
# set the pixel batch size to generate super pixel
batch_size <- 100000
# set pixel range
xrange <- c(3400,3900)
yrange <- c(1050,1600)

# This function processes raw mass spectrometry data to generate a reference peak list.
# - path: Path to the raw data (e.g., .d folder).
# - accept_Bruker_EULA_and_on_Windows_or_Linux: Set to TRUE to accept the Bruker EULA.
# - libpath: Path to the Bruker library files.
# - batch_size: The number of frames to process in each batch.
# - outref: The output file for the reference peaks. The columns are m/z, ccs and intensity for found peaks.
# - outcoord: The output file for the coordinates. The location of pixels with frame number, x and y location.
# - xrange: The x-range of the region of interest.
# - yrange: The y-range of the region of interest.
getrefpeak(path = path,accept_Bruker_EULA_and_on_Windows_or_Linux = accept_Bruker_EULA_and_on_Windows_or_Linux, batch_size = batch_size, outref = outref, outcoord = outcoord, xrange = xrange,yrange = yrange)
```

## Reference peak picking

This part will be used to find reference peaks across the sample.

### Reference peak picking

Set the parameters for peak picking and perform peak picking on super pixels. The default setting will keep all the local max peaks found in the super pixel. However, most of the peaks with smaller intensity will not be retained in the following filtering analysis and more peaks will use more computational resources for peak picking. In this case, intensity cutoff could be carefully set depending on the sensitivity of the instrument and the mean/median value of all the peaks' intensity could be the first choice.

The input of the function would be the output csv file from previous step and the output will be the reference peaks list with m/z, ccs and intensity as csv file.

```{r}
library(data.table)
dtx <- fread('refpeak.csv')
mz_ppm <- 20
ccs_tolerance <- 0.03
snr <- 3
mz_bins <- 1000
ccs_bins <- 50

# This function performs 2D peak picking.
# - dtx$mz: The m/z values.
# - dtx$ccs: The CCS values.
# - dtx$intensity: The intensity values.
# - mz_ppm: The m/z tolerance in ppm.
# - ccs_tolerance: The CCS tolerance.
# - snr: The signal-to-noise ratio cutoff.
# - mz_bins: The number of m/z bins.
# - ccs_bins: The number of CCS bins.
result <- find_2d_peaks(dtx$mz,dtx$ccs,dtx$intensity,mz_ppm,ccs_tolerance,snr,mz_bins,ccs_bins)
fwrite(result,'ref2d.csv')
# The columns are m/z, ccs and intensity for found peaks.
# retain peaks larger than mean value of all reference peaks
# sub <- result[result$intensity>mean(result$intensity),]
# fwrite(sub,'ref2d.csv')
```

# Quantitative Peaks List

This part will extract peak intensity on all pixels according to extracted reference peaks from super pixel. User need to select normalization methods such as `tic` or `rms` to normalize data and `tic` is the default value. User also need to set `zero_proportion` to remove the peaks with zero_proportion larger than a certain percentage (95% by default) of all pixels. A low `zero_proportion` will remove ions enriched in a smaller region of interests in the samples.

The input will be the RAW data and reference peaks list from previous step. The output will be normalized data with first column as location and following columns as intensitys for each reference peaks.

```{r}
# load the reference peaks
refpath = 'ref2d.csv'
# change to libtimsdata.dll for windows
lib_path <- paste0(libpath,"libtimsdata.so")
# load the raw data
path = 'PATH_TO_RAW.d'
# set normalization method tic or rms
method = 'tic'
# set zero_proportion to remove the peaks with zero_proportion larger than 95%
zero_proportion_cutoff = 0.95
# set the coord file path
coordpath = 'coord.csv'
# set the output file name
normpath = 'ticmzccs.csv'
# set pixel range
xrange <- c(3400,3900)
yrange <- c(1050,1600)
# set the uncertainty of mz and ccs
mz_ppm <- 20
ccs_tolerance <- 0.03
# This function generates a quantitative peak list.
# - refpath: Path to the reference peaks file.  The columns are m/z, ccs and intensity for found peaks.
# - lib_path: Path to the Bruker library files.
# - path: Path to the raw data.
# - method: The normalization method ('tic' or 'rms').
# - zero_proportion_cutoff: The cutoff for removing peaks with a high proportion of zeros.
# - coordpath: Path to the coordinates file.
# - normpath: The output file for the normalized peak list. The first column is the location of the pixel in X_Y format and following columns are the ions' normalized intensity found in this pixel. 
# - xrange: The x-range of the region of interest.
# - yrange: The y-range of the region of interest.
# - mz_ppm: The m/z tolerance in ppm.
# - ccs_tolerance: The CCS tolerance.
getqlist(refpath = refpath,lib_path = lib_path, path = path, method = method, zero_proportion_cutoff = zero_proportion_cutoff, coordpath = coordpath, normpath = normpath, xrange = xrange, yrange = yrange, mz_ppm = mz_ppm, ccs_tolerance = ccs_tolerance)
```

# Qualitative Peaks List

Qualitative analysis is performed with public available data for MS1-CCS database.

The input will be database csv files (provided as csv file), peaks list from previous step and the output of this step with be a csv file with annotation from the database.

## Lipid annotation

```{r}
# load database
database = 'lipidall.csv'
mode = 'pos'
peakpath = 'ticmzccs.csv'
annofile = 'annoccs.csv'

# This function annotates peaks against a lipid database.
# - database: Path to the lipid database.
# - mode: The ionization mode ('pos' or 'neg').
# - peakpath: Path to the peak list file.
# - annofile: The output file for the annotations. Results contain the database compounds' m/z and ccs in the first two columns and matched m/z and ccs in the reference peaks list. The following three columns contain name, formula, and adducts of this ions.
# - ppm: annotation mass accuracy for m/z, default 10
# - deltaccs: annotation ccs shift, default 5 
getanno(database = database,mode = mode, peakpath = peakpath, annofile = annofile)
```

## Metabolites annotation

```{r}
# load database
database = 'metaall.csv'
mode = 'pos'
peakpath = 'ticmzccs.csv'
annofile = 'metaannoccs.csv'

# This function annotates peaks against a metabolite database.
# - database: Path to the metabolite database.
# - mode: The ionization mode ('pos' or 'neg').
# - peakpath: Path to the peak list file.
# - annofile: The output file for the annotations. Results contain the database compounds' m/z and ccs in the first two columns and matched m/z and ccs in the reference peaks list. The following three columns contain name, formula, and adducts of this ions.
# - ppm: annotation mass accuracy for m/z, default 10
# - deltaccs: annotation ccs shift, default 5 
getanno(database = database,mode = mode, peakpath = peakpath, annofile = annofile)
```

## mzccsanno Shiny application

You could also use a Shiny application to make annotation with GUI.

```{r}
rmwf::runmzccsanno()
```

# Exploratory Analysis

## Data Summary

This section provides a verbose summary of the processed peak data csv file.

```{r}
# This function reads the peak file and prints a summary of its contents,
# including the number of pixels, number of features, and the ranges for
# m/z, ion mobility (CCS), and spatial coordinates.
# - "ticmzccs.csv": The path to the input peak file.
getsummary("ticmzccs.csv")
```

## Peak statistics

This part will show the distribution of peak numbers.

```{r}
# This function generates and displays plots for peak statistics.
# - "ticmzccs.csv": The path to the input peak file.
plot_peak_stats("ticmzccs.csv")
```

## Visualization

Save selected or all ion images for all reference peaks.

```{r}
# Define a vector of m/z values for which to generate ion images.
mzdemo <- c(703.5732,725.5543,739.4657,760.5806,788.6030,798.5397,826.5585)

# This function saves ion images for the specified m/z values.
# - "ticmzccs.csv": The input peak file.
# - mzdemo: A vector of m/z values.
save_ion_images("ticmzccs.csv", mzdemo)
```

## Segmentation

Segmentation can find region of interests in MSI data.

### PCA segmentation

This part will use PCA to perform segmentation.

```{r}
# This function performs PCA segmentation on the peak data.
# - "ticmzccs.csv": The input peak file.
# - "segmentation.csv": The output file for the segmentation results. 
perform_pca_segmentation("ticmzccs.csv", "segmentation.csv")
```

### UMAP segmentation

This part will use UMAP to perform segmentation.

```{r}
# This function performs UMAP segmentation on the peak data.
# - "ticmzccs.csv": The input peak file.
# - "segmentation.csv": The output file for the segmentation results.
perform_umap_segmentation("ticmzccs.csv", "segmentation.csv")
```

## Ion cluster

This part will use cosine/correlation similarity to find ion clusters with similar spatial distribution. The output csv file contain cluster number, which can be used to confirm ions cluster via images.

```{r}
# This function clusters ions based on their spatial distribution.
# - "ticmzccs.csv": The input peak file.
# - "ioncluster.csv": The output file for the ion clusters. Results contain m/z and ccs in the first two columns from reference peaks and class number based on cosine similarity with user defined cutoff.
# - hclust_cutoff: the cutoff of hierarchical clustering dendrogram
# - min_cluster_size: screen the cluster with a minimum number of ions
perform_cluster_ions(peak_file = "ticmzccs.csv", output_file = "ioncluster.csv", hclust_cutoff = 0.6, min_cluster_size = 10, folder_name = 'fullsample')
```

###  ROI specific Ion cluster for ions in certain segmentation

You can also perform ions cluster ions within a specific region of interest (ROI) from previous segmentation output csv file. 

```{r}
# This function will generate images for each clusters to help the user find the optimized cutoff.
# - "ticmzccs.csv": The input peak file.
# - "roi_ion_cluster.csv": The output file for the ROI ion clusters. Results contain m/z and ccs in the first two columns from reference peaks and class number based on cosine similarity with user defined cutoff.
# - roi_cluster: ROI cluster number.
# - hclust_cutoff: the cutoff of hierarchical clustering dendrogram
# - min_cluster_size: minium number of ions in the cluster
# loading segmentation result and select roi segmentation class number
seg <- fread("segmentation.csv")
locindex <- seg$seg == 4
perform_cluster_ions(peak_file = "ticmzccs.csv", output_file = "roi_ion_cluster.csv", locindex = locindex, hclust_cutoff = 0.8, min_cluster_size = 10, folder_name = 'roi')
```

## Reactomics analysis

This part will extract PMDs for reaction level check.

The input is the peak list csv file and the output is the reaction level csv files

```{r}
# This function performs reactomics analysis.
# - "ticmzccs.csv": The input peak file.
# - "reactomics.csv": The output file for the reactomics analysis. The first two columns are the locations of pixels and following columns are quantitative results of PMDs. Each PMD contains three columns: one from lower mass, one from higher mass and one for the sum of paired mass to show the locations of PMD.
perform_reactomics_analysis("ticmzccs.csv", "reactomics.csv")
```

###  ROI specific reactomics analysis for ions in certain segmentation

```{r}
# This function clusters ions within a specific region of interest (ROI). This function will generate images for each clusters to help the user find the optimized cutoff.
# - "ticmzccs.csv": The input peak file.
# - "roireactomics.csv": The output file for the reactomics analysis. The first two columns are the locations of pixels and following columns are quantitative results of PMDs. Each PMD contains three columns: one from lower mass, one from higher mass and one for the sum of paired mass to show the locations of PMD.
# loading segmentation result and select roi segmentation class number
seg <- fread("segmentation.csv")
locindex <- seg$seg == 4
perform_roi_reactomics_analysis("ticmzccs.csv", "roireactomics.csv", locindex = locindex)
```

###  Visualization of certain reaction (PMD)

```{r}
# This function clusters ions within a specific region of interest (ROI). This function will generate images for each clusters to help the user find the optimized cutoff.
# - "reactomics.csv": The output csv file from the reactomics analysis.
# - pmd_values: pmd value to be visualized
# - "pmd2.016.png": the figure name
save_pmd_images("reactomics.csv",pmd_values = 2.016,"pmd2.016.png")
```

## Molecular Network

This part will generate network figure.

The input is peak list csv file and annotation csv file, and the output is csv file for network generation.

```{r}
# This function generates a molecular network.
# - "ticmzccs.csv": The input peak csv file from quantitative peaks list.
# - "annoccs.csv": The annotation csv file from qualitative peaks list.
# - "molecular_network.csv": The output file for the molecular network.  The first two columns show the paired peaks of the edge, and the following two columns as m/z of paired peaks with following two columns as original and rounded mass distances. The next column is mass defect of peaks.
generate_molecular_network("ticmzccs.csv", "annoccs.csv", "molecular_network.csv")
```

### MSInet Shiny application

Please run the following chunk to get the network csv file for MSInet shiny application.

```{r}
library(pmd)
library(data.table)
dt <- fread("ticmzccs.csv",header = T)
# load ion cluster csv file
ioncluster <- fread('ioncluster.csv')
library(pmd)
data("sda")
hfpmd <- round(sda$PMD,3)
df <- rmwf::getpmddf2(dt,group = ioncluster$class,pmd=hfpmd,digits = 3)
#  The first two columns show the paired peaks of the edge, and the following two columns as m/z of paired peaks with following two columns as original and rounded mass distances. The next column is mass defect of peaks and the next one is the spatial similarity of two ions. The following two columns are group number of ions if provided by the user based results from ion cluster analysis. The last column show if the the network is local or global based on the group number.
fwrite(df,'msinet.csv')
```

Please run the following chunk to get figures for ions.

```{r}
# m/z and im
dir.create('fig')
ions <- unique(c(df$from,df$to))
mz <- sapply(strsplit(colnames(dt)[-1],'_'),function(x) round(as.numeric(x[1]),4))
im <- sapply(strsplit(colnames(dt)[-1],'_'),function(x) as.numeric(x[2]))
ions <- unique(c(df$from,df$to))
name <- paste0(mz,'_',round(im))
dt_values <- as.data.frame(dt_values)
idx <- match(ions,name)+1
sub <- dt[,..idx]
colnames(sub) <- ions
x <- sapply(strsplit(dt$location,'_'),function(x) as.numeric(x[1]))
y <- sapply(strsplit(dt$location,'_'),function(x) as.numeric(x[2]))
width=max(x)-min(x)+1
height=max(y)-min(y)+1
for(i in 1:ncol(sub)){
  dfx <- sub[,i]
  norm <- (dfx - min(dfx)) / (max(dfx) - min(dfx))
  library(RColorBrewer)
  color_palette <- colorRamp(c("skyblue", "red"))
  color_sequence <- rgb(color_palette(norm)/255,alpha=1)
  png(paste0('fig/',colnames(sub)[i],'.png'),width = width, height = height)
  plot.new()
  par(mar=c(0,0,0,0))
  plot.window(xlim = c(0,width), ylim = c(0,height), xaxs = "i", yaxs = "i", asp = NA)
  points(x-min(x)+1, y-min(y)+1, pch = 16, col = color_sequence,cex=0.3)
  dev.off()
}
```

You can start the shiny app by the following code:

```{r}
rmwf::runmsinet()
```

Then you could update network file (msinet.csv), annotation file (annoccs.csv) and images to generate network visualization for biological people.

# Differential analysis

This part will check the changes at peaks level for ion intesnity, ion numbers, as well as ion distances.

## for ions

```{r}
library(data.table)
dt <- fread("ticmzccs.csv",header = T)
dt_values <- dt[, -1, with = FALSE]

# m/z and im
mz <- sapply(strsplit(colnames(dt)[-1],'\\_'),function(x) round(as.numeric(x[1]),4))
im <- sapply(strsplit(colnames(dt)[-1],'\\_'),function(x) as.numeric(x[2]))

# define pixel level groups, here using segmentation
seg <- fread('segmentation.csv',header=T)
library(genefilter)
re <- colFtests(as.matrix(dt_values),factor(ifelse(seg$umap==2,'islet','non-islet')))

# fold change
fcall <- c()
df <- as.matrix(dt_values)
group <- factor(ifelse(seg$umap==2,'islet','non-islet'))
for (i in 1:ncol(dt_values)){
  t <- aggregate(df[,i],by=list(group),mean)
  fc <- t[1,2]/t[2,2]
  fcall <- c(fcall,fc)
}
fcall[is.na(fcall)] <- 0
re$adj <- p.adjust(re$p.value,'BH')

# filter with p value and fold change
sum(re$adj<0.05&!is.na(re$adj)&(fcall>1.5|fcall<0.67))/length(re$adj)
```

## for ion numbers

```{r}
library(data.table)
dt <- fread("ticmzccs.csv",header = T)
dt[, np := rowSums(.SD != 0)]
seg <- fread('segmentation.csv',header=T)
seg$np <- dt$np
seg$islet <- factor(ifelse(seg$umap==2,'islet','non-islet'))
library(ggplot2)
ggplot(seg,aes(np)) +
  ggtitle('peak number for each pixel')+
  geom_histogram(binwidth=1)+theme_bw()

dt_values <- as.matrix(dt[, -1, with = FALSE])
num <- apply(dt_values,2,function(x) sum(x!=0))
num <- data.frame(num=num)
ggplot(num,aes(num)) +
  ggtitle('pixel number for each peaks')+
  geom_histogram()+theme_bw()

ggplot(seg, aes(x = np, y = islet)) + 
  ggtitle('pixel number for different group')+
  geom_density_ridges()+theme_bw()
# t.test for pixel number
for(i in c(1:length(unique(seg$pca)))){
  xyi <- seg[seg$pca==i,]
  if(length(unique(xyi$islet))>1){
    print(t.test(xyi$np~xyi$islet))
  }
}
```

## for ion distance

```{r}
library(distances)
# Check ion average distance for one group called islet
dfislet <- dt_values[seg$umap==3,]
dfnoislet <- dt_values[seg$umap!=3,]
d2 <- d1 <- c()
for(i in c(1:length(mz))){
  xyi <- as.data.frame(seg)[dfislet[,i]!=0,]
  # set pixel number 0.5-30% of all pixels to ensure sparsity
  if(nrow(xyi)>0.005*nrow(dfislet)&nrow(xyi)<0.9*nrow(dfislet)){
    dt <- distances(xyi[,c(1,2)])
    #d1 <- c(d1,median(dt))
    d2 <- c(d2,mean(dt))
  }else{
    d2 <- c(d2,NA)
  }
}
# Check ion average distance for one group called dfold
d4 <- d3 <- c()
for(i in c(1:length(mz))){
  xyi <- as.data.frame(seg)[dfnoislet[,i]!=0,]
  # set pixel number 0.5-30% of all pixels to ensure sparsity
  if(nrow(xyi)>0.005*nrow(dfnoislet)&nrow(xyi)<0.9*nrow(dfnoislet)){
    dt <- distances(xyi[,c(1,2)])
    #d1 <- c(d1,median(dt))
    d4 <- c(d4,mean(dt))
  }else{
    d4 <- c(d4,NA)
  }
}
# t test and visulization of differences
xx <- cbind.data.frame(dis=c(d2,d4),group=c(rep('islet',length(d2)),rep('nosilet',length(d4))))
library(ggplot2)
library(ggridges)
xx <- xx[complete.cases(xx),]
ggplot(xx, aes(dis,group)) +
  geom_density_ridges()+theme_bw()

t.test(xx$dis~xx$group)
```

# Scale the spatial resolution

```{r}
library(data.table)
dt <- fread("ticmzccs.csv",header = T)
dt_values <- dt[, -1, with = FALSE]

# location
dt$x <- sapply(strsplit(dt$location,'\\_'),function(x) as.numeric(x[1]))
dt$y <- sapply(strsplit(dt$location,'\\_'),function(x) as.numeric(x[2]))

x_min <- min(dt$x, na.rm = TRUE)
x_max <- max(dt$x, na.rm = TRUE)
y_min <- min(dt$y, na.rm = TRUE)
y_max <- max(dt$y, na.rm = TRUE)

# scale factor setting
n <- 5
new_x_size <- floor((x_max - x_min) / n) + 1
new_y_size <- floor((y_max - y_min) / n) + 1
x_new <- seq(x_min, x_max, length.out = new_x_size)
y_new <- seq(y_min, y_max, length.out = new_y_size)
new_coords <- as.data.table(expand.grid(x_new, y_new))
setnames(new_coords, c("x", "y"))

dt[, new_x := round((x - x_min) / n) * n + x_min]
dt[, new_y := round((y - y_min) / n) * n + y_min]

new_features_dt <- dt[, lapply(.SD, function(x) sum(x, na.rm = TRUE)), by = .(new_x, new_y), .SDcols = -c("location", "x", "y")]

new_features_dt <- new_features_dt[rowSums(new_features_dt[, -c("new_x", "new_y"), with = FALSE]) != 0]
# generate scaled data and coords
new_features <- as.matrix(new_features_dt[, -c("new_x", "new_y"), with = FALSE])
new_coords <- new_features_dt[, .(new_x, new_y)]
```

# Anatomy co-registration

## MSI2TIC

This step will generate image for MSI with outline for registration purpose.

```{r}
library(data.table)
dt <- fread("ticmzccs.csv",header = T)
df <- dt[, -1, with = FALSE]

# location
x <- sapply(strsplit(dt$location,'\\_'),function(x) as.numeric(x[1]))
y <- sapply(strsplit(dt$location,'\\_'),function(x) as.numeric(x[2]))

# m/z and im
mz <- sapply(strsplit(colnames(dt)[-1],'\\_'),function(x) round(as.numeric(x[1]),4))
im <- sapply(strsplit(colnames(dt)[-1],'\\_'),function(x) as.numeric(x[2]))

xy <- data.frame(x=x,y=y)

# pixel by pixel for coords
nxy <- cbind.data.frame(x=xy$x-min(xy$x)+1,y=xy$y-min(xy$y)+1)

# define outline pixels
outline <- 50
# fill intensity
tic <- summarizePixels(one, c(tic="mean"))
nxy$i <- apply(df,1,sum)
# add outline
nnxy <- cbind.data.frame(x=xy$x-min(xy$x)+1+outline,y=xy$y-min(xy$y)+outline+1)
write.csv(nnxy,'outline.csv')

png("msitic.png", width = max(xy$x)-min(xy$x)+2*outline+1,height = max(xy$y)-min(xy$y)+2*outline+1)
plot.new()
par(mar=c(0,0,0,0))
plot.window(xlim = c(-outline, max(nxy$x)+outline), ylim = c(-outline, max(nxy$y)+outline), xaxs = "i", yaxs = "i", asp = NA)
points(nxy$x, nxy$y, pch = 16, col = nxy$i,cex=0.3)
dev.off()
```

## Geojson2img

This step will adjust geojson from QuPath annotation to the same scale with MSI and output image for registration.

```{r}
xy <- read.csv('outline.csv',row.names = 1)
jsonpath <- "outline.geojson"
geojson <- sf::st_read(jsonpath)
coords <- sf::st_coordinates(geojson$geometry)
width <- max(xy$x)-min(xy$x)+1
height <- max(xy$y)-min(xy$y)+1
outline <- 50
rangew <- max(coords[,1])-min(coords[,1])+1
rangeh <- max(coords[,2])-min(coords[,2])+1
png("he.png", bg = "transparent",width = width+outline*2,height = height+outline*2)
par(mar=c(0,0,0,0))
plot(geojson$geometry,setParUsrBB=T,col = 'green',xlim=c(min(coords[,1])-rangew/width*outline,max(coords[,1])+rangew/width*outline),ylim=c(min(coords[,2])-rangeh/height*outline,max(coords[,2])+rangeh/height*outline))
dev.off()
```

## Rotate image

This step will rotate the image for registration.

```{r}
library(magick)
new <- image_read("he.png")
# rotate
image_rotate(new, 180) %>% image_write("he.png")
```

## H&EMSIReg

Use simpleITK for registration.

```{r}
# image_viewer <- ImageViewer()
# image_viewer$SetApplication('/Applications/ITK-SNAP.app/Contents/MacOS/ITK-SNAP')
alpha = 0.5
library(SimpleITK)
fixed_image <- ReadImage("outline.png", 'sitkFloat32')
moving_image <- ReadImage("he.png", 'sitkFloat32')
initial_transform <- CenteredTransformInitializer(fixed_image, 
                                                  moving_image, 
                                                  Euler2DTransform(), 
                                                  "GEOMETRY")
# initial image
moving_resampled <- Resample(moving_image, fixed_image, initial_transform)
registration_method <- ImageRegistrationMethod()
# Similarity metric settings.
registration_method$SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)
registration_method$SetMetricSamplingStrategy("RANDOM")
registration_method$SetMetricSamplingPercentage(0.01)
registration_method$SetInterpolator("sitkLinear")

# Optimizer settings.
registration_method$SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, convergenceMinimumValue=1e-6, convergenceWindowSize=10)
registration_method$SetOptimizerScalesFromPhysicalShift()

# Setup for the multi-resolution framework.            
registration_method$SetShrinkFactorsPerLevel(shrinkFactors = c(4,2,1))
registration_method$SetSmoothingSigmasPerLevel(smoothingSigmas=c(2,1,0))
registration_method$SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()

# Don't optimize in-place, we would possibly like to run this cell multiple times.
registration_method$SetInitialTransform(initial_transform, inPlace=FALSE)
final_transform <- registration_method$Execute(fixed_image, moving_image)
# generate aligned image
moving_resampled <- Resample(moving_image, fixed_image, final_transform)
WriteTransform(final_transform, "reg.tfm")
# WriteImage(moving_resampled, 'age6align.tiff')
# image_viewer$Execute((1-alpha)*fixed_image + alpha*moving_resampled)
```

## Coordsreg

This step will convert coords by the registration.

```{r}
tf <- ReadTransform('reg.tfm')
fixed_image <- ReadImage("outline.png", 'sitkFloat32')
# this is the field coords
coord_transform = SimpleITK::TransformToDisplacementFieldFilter()
coord_transform$SetReferenceImage(fixed_image)
coord_transform$SetOutputSpacing(fixed_image$GetSpacing())
coord_transform$SetOutputOrigin(fixed_image$GetOrigin())
coord_transform$SetSize(fixed_image$GetSize())
displacement_field = coord_transform$Execute(tf)

jsonpath <- "outline.geojson"
library(sf)
geojson <- sf::st_read(jsonpath)

pixel <- 'outline.csv'
xy <- read.csv(pixel,row.names = 1)

changexy2 <- function(x){
  coords <- st_coordinates(x)
  mt <- coords[,c('X','Y')]
  width <- max(xy$x)-min(xy$x)+1
  height <- max(xy$y)-min(xy$y)+1
  outline <- 50
  rangew <- max(coords[,1])-min(coords[,1])+1
  rangeh <- max(coords[,2])-min(coords[,2])+1
  mt[,1] <- (mt[,1]-min(coords[,1])+1)*width/rangew+outline
  mt[,2] <- (mt[,2]-min(coords[,2])+1)*height/rangeh+outline
  mt[,1] <- width+2*outline - mt[,1]
  mt[,2] <- height+2*outline - mt[,2]
  fe <- split.data.frame(mt,coords[,'L2'])
  nmt <- lapply(fe,function(x) list(t(apply(x,1,function(y) y+displacement_field$GetPixel(y)))))
  nmt
}
# perform registration
re <- changexy2(geojson$geometry)
# remove wrong annotation
sfobj <- st_sfc(st_multipolygon(re[-c(153,176,180,189,121)]))
# get the surrounding pixel with 3 pixel as distance
sfobjoutline <- st_buffer(sfobj, dist = 3)
plot(sf::st_geometry(sfobj),setParUsrBB=T,col = 'green')
# 18,106,122,147,170,175
# 14,114,137,143,148
# for(i in c(107:183)) st_sfc(st_multipolygon(re[i]))
```

## Anno2MSI

This step will map the annotation back to MSI pixel.

```{r}
## MSI image2json
pixel <- 'outline.csv'
pixel_coords <- read.csv(pixel,row.names = 1)
point <- st_cast(st_sfc(st_multipoint(as.matrix(pixel_coords),dim = 'XY')),"POINT")
pixel_coords$i <- st_intersects(point, sfobj) %>% lengths > 0
sum(pixel_coords$i)
pixel_coords$b <- st_intersects(point, sfobjoutline) %>% lengths > 0
sum(pixel_coords$b)

num <- rep(NA,length(pixel_coords$x))
sfobjt <- sfobj[[1]]
for (i in c(1:length(sfobjt))){
  x <- unlist(st_intersects(st_polygon(sfobjt[[i]]),point))
  num[x] <- i
}

pixel_coords$num <- num

sfobjbu <- sfobjoutline[[1]]
for (i in c(1:length(sfobjbu))){
  x <- unlist(st_intersects(st_polygon(sfobjbu[[i]]),point))
  num[x] <- i
}

pixel_coords$numb <- num

write.csv(pixel_coords,'anno.csv')
```

## MSI viz

Display the annotated MSI region.

```{r}
anno <- read.csv('anno.csv',row.names = 1)
annomsi <- df[anno$i,]
library(irlba)
svd_result <- irlba(df, nv = 20)
pca_scores <- df %*% svd_result$v

library(ClusterR)
opt = Optimal_Clusters_KMeans(as.data.frame(pca_scores), max_clusters = 10, plot_clusters = T, criterion = 'silhouette',initializer = 'optimal_init', tol_optimal_init = 0.2)
km = KMeans_arma(as.matrix(pc_scores), clusters = 2, n_iter = 10, seed_mode = "random_subset", verbose = T, CENTROIDS = NULL)
pr = predict_KMeans(as.matrix(pc_scores), km)
plot(xy$x,xy$y,col=pr,cex=.1)

plot(annomsi)
png("anno.png", bg = "transparent",width = 823,height = 1192)
par(mar=c(0,0,0,0))
plot(xy$x,xy$y,col=as.vector(pr),cex=0.01,pch=19)
dev.off()
```
